{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\g0035\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "5 [0 0 0 0 0 1 0 0 0 0]\n",
      "0 [[1 0 0 0 0 0 0 0 0 0]]\n",
      "1 [[0 1 0 0 0 0 0 0 0 0]]\n",
      "2 [[0 0 1 0 0 0 0 0 0 0]]\n",
      "3 [[0 0 0 1 0 0 0 0 0 0]]\n",
      "4 [[0 0 0 0 1 0 0 0 0 0]]\n",
      "5 [[0 0 0 0 0 1 0 0 0 0]]\n",
      "6 [[0 0 0 0 0 0 1 0 0 0]]\n",
      "7 [[0 0 0 0 0 0 0 1 0 0]]\n",
      "8 [[0 0 0 0 0 0 0 0 1 0]]\n",
      "9 [[0 0 0 0 0 0 0 0 0 1]]\n",
      "WARNING:tensorflow:From c:\\users\\g0035\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.5619 - accuracy: 0.8349\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 11s 175us/step - loss: 0.2521 - accuracy: 0.9222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x127a0e137b8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Adapted from: https://docs.python.org/3/library/gzip.html\n",
    "\n",
    "import gzip\n",
    "\n",
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "type(file_content)\n",
    "\n",
    "file_content[0:4]\n",
    "\n",
    "\n",
    "# Adapted from: https://stackoverflow.com/questions/51220161/how-to-convert-from-bytes-to-int\n",
    "\n",
    "int.from_bytes(file_content[0:4], byteorder='big')\n",
    "\n",
    "\n",
    "int.from_bytes(file_content[4:8], byteorder='big')\n",
    "\n",
    "\n",
    "int.from_bytes(file_content[8:12], byteorder='big')\n",
    "\n",
    "int.from_bytes(file_content[12:16], byteorder='big')\n",
    "\n",
    "int.from_bytes(file_content[278:279], byteorder='big')\n",
    "\n",
    "l = file_content[16:800]\n",
    "\n",
    "type(l)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "image = ~np.array(list(file_content[16:800])).reshape(28,28).astype(np.uint8)\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# Import keras.\n",
    "import keras as kr\n",
    "\n",
    "# Adapted from: https://docs.python.org/3/library/gzip.html\n",
    "\n",
    "import gzip\n",
    "\n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    labels = f.read()\n",
    "\n",
    "# Start a neural network, building it by layers.\n",
    "model = kr.models.Sequential()\n",
    "\n",
    "# Add a hidden layer with 1000 neurons and an input layer with 784.\n",
    "model.add(kr.layers.Dense(units=600, activation='linear', input_dim=784))\n",
    "model.add(kr.layers.Dense(units=400, activation='relu'))\n",
    "# Add a three neuron output layer.\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "# Build the graph.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_img = f.read()\n",
    "\n",
    "with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_lbl = f.read()\n",
    "    \n",
    "train_img = ~np.array(list(train_img[16:])).reshape(60000, 28, 28).astype(np.uint8) / 255.0\n",
    "train_lbl =  np.array(list(train_lbl[ 8:])).astype(np.uint8)\n",
    "inputs = train_img.reshape(60000, 784)\n",
    "\n",
    "# For encoding categorical variables.\n",
    "import sklearn.preprocessing as pre\n",
    "\n",
    "encoder = pre.LabelBinarizer()\n",
    "encoder.fit(train_lbl)\n",
    "outputs = encoder.transform(train_lbl)\n",
    "\n",
    "print(train_lbl[0], outputs[0])\n",
    "\n",
    "for i in range(10):\n",
    "    print(i, encoder.transform([i]))\n",
    "\n",
    "\n",
    "model.fit(inputs, outputs, epochs=2, batch_size=100)\n",
    "\n",
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_img = f.read()\n",
    "\n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_lbl = f.read()\n",
    "    \n",
    "test_img = ~np.array(list(test_img[16:])).reshape(10000, 784).astype(np.uint8) / 255.0\n",
    "test_lbl =  np.array(list(test_lbl[ 8:])).astype(np.uint8)\n",
    "\n",
    "\n",
    "(encoder.inverse_transform(model.predict(test_img)) == test_lbl).sum()\n",
    "\n",
    "model.predict(test_img[5:6])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(test_img[5].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x127a1f440f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(test_img[4].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
